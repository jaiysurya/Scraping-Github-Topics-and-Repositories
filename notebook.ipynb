{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Topics and their top repositories from Github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping\n",
    "Web scraping is the process of collecting structured web data in an automated fashion. Itâ€™s also known as web data extraction. Some of the main use cases of web scraping include price monitoring, price intelligence, news monitoring, lead generation, and market research among many others.\n",
    "In general, web data extraction is used by people and businesses who want to make use of publicly available web data to make smarter decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Github\n",
    "GitHub, Inc. is an Internet hosting service for software development and version control using Git. It provides the distributed version control of Git plus access control, bug tracking, software feature requests, task management, continuous integration, and wikis for every project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "In this web scraping project, we are going to scrape the data from github. The requirement is to scrape the topics available from github and their top repositories. we are going to use Python Programming language for this project. With the help of `requests` library we are downloading a webpage and with the help of `BeautifulSoup` library we are going to extract and parse the information from the webpage. We also make use of other libraries such as `pandas` to create dataframe of our results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "* Initially, we are scraping https://github.com/topics. To get a list of topics.\n",
    "* For each topic, we are extracting their title, description and the topic page url.\n",
    "* As a next step, we are getting the top 25 repositories for each topic\n",
    "* For each repository, we are going to extract the `repo_name`, `user_name`, `repo_url`, `stars` and download it in a csv format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
